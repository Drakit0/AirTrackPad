{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "        frame.flags.writeable = False\n",
    "        results = hands.process(frame)\n",
    "\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS) \n",
    "                    # ,mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    # mp_drawing_styles.get_default_hand_connections_style())\n",
    "        cv2.imshow('MediaPipe Hands', frame)\n",
    "        if cv2.waitKey(5) & 0xFF == 27: # Press esc to quit\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "\n",
    "               \n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    original_frame = cv2.imread(\"raw_data/palms_test.jpg\")\n",
    "\n",
    "    frame = cv2.cvtColor(cv2.flip(original_frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    frame.flags.writeable = False\n",
    "    results = hands.process(frame)\n",
    "\n",
    "    frame.flags.writeable = True\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS) \n",
    "                # ,mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                # mp_drawing_styles.get_default_hand_connections_style())\n",
    "                \n",
    "cv2.imshow('MediaPipe Hands', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.0830296\n",
      "y: 0.773183227\n",
      "z: 6.02224134e-007\n",
      " x: 0.954928875\n",
      "y: 0.875744\n",
      "z: 5.91532171e-007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.multi_hand_landmarks[0].landmark[0], results.multi_hand_landmarks[1].landmark[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify with sobel, prewitt, canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Sobel\n",
    "sobel = ski.filters.sobel(gray_frame)\n",
    "\n",
    "# Canny\n",
    "canny = ski.feature.canny(gray_frame, low_threshold = 100, high_threshold = 200)\n",
    "\n",
    "# Prewitt\n",
    "prewitt = ski.filters.prewitt(gray_frame)\n",
    "\n",
    "cv2.imshow('Sobel', sobel) # Less computational cost\n",
    "cv2.imshow('Canny', canny) # More precise\n",
    "cv2.imshow('Prewitt', prewitt)\n",
    "cv2.moveWindow(\"Prewitt\", 100, 200)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWinÂºdows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminate noise with mog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(videopath):\n",
    "    \"\"\"\n",
    "    Reads a video file and returns its frames along with video properties.\n",
    "\n",
    "    Args:\n",
    "        videopath (str): The path to the video file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - frames (list): A list of frames read from the video.\n",
    "            - frame_width (int): The width of the video frames.\n",
    "            - frame_height (int): The height of the video frames.\n",
    "            - frame_rate (float): The frame rate of the video.\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO: Complete this line to read the video file\n",
    "    cap = cv2.VideoCapture(videopath) \n",
    "    \n",
    "    #TODO: Check if the video was successfully opened\n",
    "    if not cap.isOpened():\n",
    "        print('Error: Could not open the video file')\n",
    "\n",
    "    #TODO: Get the szie of frames and the frame rate of the video\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # Get the width of the video frames\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Get the height of the video frames\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS) # Get the frame rate of the video\n",
    "    \n",
    "    #TODO: Use a loop to read the frames of the video and store them in a list\n",
    "    frames = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frames.append(frame)\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    return frames, frame_width, frame_height, int(frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "output_folder = \"processed_data/mog\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "histories = [200]  # Number of frames to use to build the background model\n",
    "nmixtures = [7]  # Number of Gaussian mixtures\n",
    "background_ratios = [0.5]  # Background ratio to consider a pixel as background\n",
    "\n",
    "for history in histories: \n",
    "    for mixture in nmixtures:\n",
    "        for ratio in background_ratios:\n",
    "            \n",
    "            mog = cv2.bgsegm.createBackgroundSubtractorMOG(history, mixture, ratio, 0) # 0 means an automatic noise reduction    \n",
    "\n",
    "            # Name of the output video file with the parameters (history, varThreshold, detectShadows)\n",
    "            videoname = f'mog_{history}_{mixture}_{ratio}.mp4' # Name of the output video file with the parameters\n",
    "            videoname = os.path.join(output_folder, videoname)\n",
    "            \n",
    "            # Create a VideoWriter object to save the video\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\") # Codec to use\n",
    "            frame_size = (int(cam.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))) # Size of the frames\n",
    "            fps = cam.get(cv2.CAP_PROP_FPS) # Frame rate of the video\n",
    "            out_mog = cv2.VideoWriter(videoname, fourcc, fps, frame_size)\n",
    "            out_canny = cv2.VideoWriter(output_folder+'/canny.mp4', fourcc, fps, frame_size)\n",
    "            out_sobel = cv2.VideoWriter(output_folder+'/sobel.mp4', fourcc, fps, frame_size)\n",
    "\n",
    "            while cam.isOpened():\n",
    "                ret, frame = cam.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "\n",
    "                # Apply the MOG algorithm to detect the moving objects\n",
    "                mask = mog.apply(frame)\n",
    "                # Convert to BGR the mask to store it in the video\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "                # Save the mask in a video\n",
    "                out_mog.write(mask)\n",
    "\n",
    "                canny_processed = ski.feature.canny(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)) # , mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "                canny_processed = cv2.cvtColor((canny_processed*255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "                sobel_processed = ski.filters.sobel(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)) # , mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "                sobel_processed = cv2.cvtColor((sobel_processed * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "                out_canny.write(canny_processed)\n",
    "                out_sobel.write(sobel_processed)\n",
    "\n",
    "                cv2.imshow('MOG Mask', mask)\n",
    "                cv2.imshow('Canny', canny_processed)\n",
    "                cv2.imshow('Sobel', sobel_processed)\n",
    "                \n",
    "                if cv2.waitKey(5) & 0xFF == 27:  # Press esc to quit\n",
    "                    break\n",
    "\n",
    "            out_mog.release()\n",
    "            out_canny.release()\n",
    "            out_sobel.release()\n",
    "            \n",
    "            \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
